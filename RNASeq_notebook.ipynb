{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, get the data.\n",
    "\n",
    "For this tutorial we'll use available data from the study \"Transcriptome Dynamics of the Stomatal Lineage: Birth, Amplification, and Termination of a SelfRenewing Population\" by the Bergman group [link to the study] (https://www.ncbi.nlm.nih.gov/pubmed/25850675). \n",
    "\n",
    "Data is under the project PRJNA253731 (SRA: SRP043607) and can be found in [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE58856).\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE58856\n",
    "\n",
    "\n",
    "\n",
    "** Note **\n",
    "The experiment also contains microarray samples (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE58856). Be sure to get the SRA samples which are the RNAseq files (GSE58857).\n",
    "\n",
    "\n",
    "* The matrix contains information about the experiment: ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE58nnn/GSE58856/matrix/\n",
    "* Some supplementary files:L\n",
    "    * ftp://ftp.ncbi.nlm.nih.gov/pub/geo/DATA/supplementary/series/GSE58856/GSE58856_RNASeq_Adrian_et_al_2014.txt.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Experiment Description **\n",
    "\n",
    "Run in R:\n",
    "\n",
    "```\n",
    "library(\"GEOquery\")\n",
    "\n",
    "setwd(\"~/Desktop/RNASeq_Pipeline/\")\n",
    "dir.create(\"RawData\",showWarnings = F)\n",
    "##\n",
    "gse <- getGEO(\"GSE58857\", GSEMatrix = TRUE,destdir = \"RawData/\")\n",
    "show(gse)\n",
    "names(gse$GSE58856_series_matrix.txt.gz)\n",
    "meta <- as(gse$GSE58856_series_matrix.txt.gz,\"data.frame\")\n",
    "write.csv(file = \"meta/metaData_GSE58857.csv\",x = meta,quote = F,row.names = T)\n",
    "```\n",
    "\n",
    "The resulting table contains information about the experiment.\n",
    "\n",
    "The experiment consists of protplasts separated by FACS. They range from epidermis cells, to mother and mature guard cells. To make this analysis faster we'll focus in epidermis and mature guard cells.\n",
    "\n",
    "If we take a look at the table:\n",
    "\n",
    "``meta[,c(\"source_name_ch1\",\"title\",\"relation\"),drop=F]``\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "\n",
    "** To download SRA data set use the SRA toolkit**\n",
    "\n",
    "https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=std\n",
    "\n",
    "(Download the compiled binary and add it to your path.)\n",
    "\n",
    "Example: https://www.biostars.org/p/111040/\n",
    "\n",
    "\n",
    "These are files of ~1GB each so it may take some time to download them.\n",
    "\n",
    "\n",
    "|SRR| Sample | Source |\n",
    "|---|---| --- |\n",
    "|``SRR1463325``| RNASeq - ML1p::YFP-RCI2A (ML1Y) - replicate 1 | \tEpidermis cells |\n",
    "|``SRR1463326``| RNASeq - ML1p::YFP-RCI2A (ML1Y) - replicate 2 |\tEpidermis cells |\n",
    "|``SRR1463334``| RNASeq - E1728::GFP (E1728G) - replicate 1  | Mature guard cells|\n",
    "|``SRR1463335``| RNASeq - E1728::GFP (E1728G) - replicate 2 | Mature guard cells|\n",
    "\n",
    "Let's use wget to download these files:\n",
    "\n",
    "Create a folder to store the files (``mkdir OriginalFiles``) and move into that folder.\n",
    "\n",
    ">``wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByExp/sra/SRX/SRX627/SRX627394/SRR1463325/SRR1463325.sra``\n",
    "\n",
    "> ``wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByExp/sra/SRX/SRX627/SRX627395/SRR1463326/SRR1463326.sra``\n",
    "\n",
    "> ``wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP043/SRP043607/SRR1463334/SRR1463334.sra``\n",
    "\n",
    "> ``wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP043/SRP043607/SRR1463335/SRR1463335.sra``\n",
    "\n",
    "\n",
    "And convert them to fastq files:\n",
    "\n",
    ">``for each in *.sra; do echo $each; fastq-dump --gzip $each .; done``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Practices on RNASeq data.\n",
    "\n",
    "Treat your data preciously. It takes a lot of effort and money to produce, so any accidental corruption of the files might result in a severe stepback.\n",
    "\n",
    "One thing I learned when analyzing RNA seq data (and in principle one should do this with any type of raw data) was to protect and use soft symbolic links (think of it like direct access) to access it or modify the filenames. Personally I never modify the names of the raw files. If I need to do it I usually do it on the symbolic links or change the name on downstream files during the analysis using a metadata file.\n",
    "\n",
    "Inside the OriginalFiles folder change the writing permissions for the files\"\n",
    "\n",
    "> `cd OriginalFiles`\n",
    "> `chmod -w *`\n",
    "> `cd ..`\n",
    "\n",
    "\n",
    "Then create a new folder and create symbolic links to the original files.\n",
    "\n",
    "> `mkdir RawData`\n",
    "> `cd RawData`\n",
    "> `ln -s ../OriginalFiles/* . #Create a soft link`\n",
    "\n",
    "Check the files, they're still readable but they point to another location. If we accidentally modify or delte these files the original files won't be affected\n",
    "\n",
    "> `ll -h`\n",
    "> `gunzip -dc SRR1463325.fastq.gz | head`\n",
    "> `cd .. # Exit to the main folder.`\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quality Control on Raw Samples\n",
    "\n",
    "<p>Let's take a look at the raw samples. It's important to check the quality of the sequences before even start the analysis. We can get an idea if something went wrong during the sequencing process, how much adapter contamination we have and if barcodes have to be trimmed.</p>\n",
    "\n",
    "To make this tutorial faster let's just run one sample at a time. \n",
    "\n",
    "#### Before we begin.\n",
    "\n",
    "Normally data like this should be run on a server, but for the purposes of this tutorial we'll look at a subset of the reads. Let's use the first 200,000 reads:\n",
    "\n",
    "> `gunzip -dc RawData/SRR1463325.fastq.gz | head -n 800000 > RawData/testSeq.fastq` <br>\n",
    "> `gzip RawData/testSeq.fastq`\n",
    "\n",
    "<center>__Q: I set the lines to 800,000 even though we only want 200,000 reads. Do you know why?__</center>\n",
    "\n",
    "\n",
    "### Run fastqc\n",
    "\n",
    "Get acquainted with what fastqc does and what each module means: http://www.bioinformatics.babraham.ac.uk/projects/fastqc/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> `mkdir -p 00QC/Raw` <br>\n",
    "> `fastqc RawData/testSeq.fastq.gz -o 00QC/Raw/`\n",
    "\n",
    "Open the html generated inside the folder and take a look at the report. \n",
    "\n",
    "Since we're using only the first 200,000 sequences (out of 36,145,497) the report won't look too bad. \n",
    "If you check the _kmer content_ tab you'll see that the first ~12 bp have an increased overrepresentation of k-mers. This might be due to barcodes or adapters during the RNAseq. We need to trim these before we align the reads to the genome.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "If you want to run all samples (not recommended on your desktop), do:\n",
    "\n",
    "> ``fastqc RawData/*.fastq.gz --noextract -o 00QC/Raw``\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 2. Remove Adapters/Clean Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Adapter Contamination **\n",
    "\n",
    "It is necessary to remove in short reads (~50bp) but not quite in longer reads (>100bp). \n",
    "\n",
    "\n",
    "Test known adapters with by with `grep`.\n",
    "\n",
    "ie: <br>\n",
    "``gunzip -dc SRR1463326.fastq.gz | grep \"ATCTCGTATGCCGTCTTCTGCTTG\"``\n",
    "                                   \n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAAT**ATCTCGTATGCCGTCTTCTGCTTG**\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAAT**ATCTCGTATGCCGTCTTCTGCTTG**\n",
    "AATAACGTAACGTAATATCATC**ATCTCGTATGCCGTCTTCTGCTTG**AAAAAAAAAAATA\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGATCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGGCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACCCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCAGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "AAAAATAACGTAACGTAATATCATCATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAA\n",
    "GGAAGAGCACACGTCTGAACTCCAGTCACGCCAATATCTCGTATGCCGTCTTCTGCTTG\n",
    "\n",
    "\n",
    "The sequence corresponds to the v1.5 Small RNA 3' Adapter from the Illumina. Other potential contaminating sequences * could be:\n",
    "\n",
    "* GATCGGAAGAGCACACGTCTGAACTCCAGTCAC\n",
    "\n",
    "\n",
    "See: https://support.illumina.com/content/dam/illumina-support/documents/documentation/chemistry_documentation/experiment-design/illumina-adapter-sequences_1000000002694-01.pdf.\n",
    "\n",
    "--- <br>\n",
    "\n",
    "__ minion and the Kraken suite__ \n",
    "If the adapter sequence is not known, the program `minion` is part of the [Kraken suite](https://www.ebi.ac.uk/research/enright/software/kraken) which are tools developed for the preprocessing of sequencing reads (adapter inference/trimming, minimizing redundancy).\n",
    "\n",
    "`minion` is designed to infer the presence of an adapter reading the first 2 million reads. If you want to change the number of reads use the paramter `-do <NUMBER>` to change this:\n",
    "\n",
    "* To infer the adapter:\n",
    "\n",
    ">``minion search-adapter -i SRR1463326.fastq #-do 200000``\n",
    "\n",
    "* To test a sequence\n",
    "\n",
    "> ``minion search-adapter -i SRR1463326.fastq -adapter ATCTCGTATGCCGTCTTCTGCTTG #-do 200000``\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "** Removing barcodes **\n",
    "\n",
    "If there are still barcodes present in the data ``fastx_trimmer`` from the ``fastx`` toolkit can be used.\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "``fastx_trimmer -v -f 9 -Q33`` to remove the first 8bp.\n",
    "\n",
    "\n",
    "** Code used **\n",
    "\n",
    "First, input the adapter and tabu sequences:\n",
    "\n",
    "   \n",
    "> ``tabu=\"GATCGGAAGAGCACACGTCTGAACTCCAGTCAC\"`` <br>\n",
    "> ``adapter=\"ATCTCGTATGCCGTCTTCTGCTTG\"``\n",
    "\n",
    "If we look at the K-mer content in the QC analysis we can see a high content of kmers in the first 10-12 nt. Let's go ahead and clip these parts of the read. We don't want to lose a lot of information (the longer the read, the better the mapping) but since these low complexity sequences are at the beggining of the read they could harm downstream analysis. Let's clip the first 11 nt. Set with `-f` set to 12 (cut the first 11 nt) for  `fastx_trimmer`. \n",
    "\n",
    "\n",
    "Create a folder to store the trimmed sequences:\n",
    ">``mkdir 01_trimmed`` <br>\n",
    "\n",
    "Run:\n",
    "> ``for n in RawData/*test*.fastq.gz; do tmp=`basename $n`; tmp=${tmp%.fastq.gz}; echo Doing $tmp; gunzip -dc $n | fastx_trimmer -v -f 12 -Q33 - | reaper -geom no-bc -tabu $tabu -3pa $seqAdapt -noqc -dust-suffix 6/ACTG -dust-suffix-late 6/ACTG -nnn-check 1/1 -qqq-check 35/10 -clean-length 30 -tri 10 -polya 5 -basename 01_trimmed/$tmp ;done``\n",
    "\n",
    "\n",
    "\n",
    "For more info on the parameters see [reaper](http://wwwdev.ebi.ac.uk/enright-dev/kraken/reaper/src/reaper-latest/doc/reaper.html) and [fastx](http://hannonlab.cshl.edu/fastx_toolkit/)\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "If you want to run all samples (not recommended on your desktop), do:\n",
    "\n",
    "> ``for n in RawData/*fastq.gz; do tmp=`basename $n`; tmp=${tmp%.fastq.gz}; echo Doing $tmp; gunzip -dc $n | fastx_trimmer -v -f 12 -Q33 - | reaper -geom no-bc -tabu $tabu -3pa $seqAdapt --noqc -dust-suffix 6/ACTG -dust-suffix-late 6/ACTG -nnn-check 1/1 -qqq-check 35/10 -clean-length 30 -tri 10 -polya 5 -basename 01_trimmed/$tmp ;done``\n",
    "\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 3. Quality Control on Clean Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Let's take a look on the trimmed reads and compare with the raw data.\n",
    "\n",
    "Create a folder to store the files:\n",
    "> ``mkdir 00QC/trimmed`` <br>\n",
    "\n",
    "Run fastqc:\n",
    "> ``fastqc 01_trimmed/*test*.lane.clean.gz -o 00QC/trimmed``\n",
    "\n",
    "\n",
    "At least on our test data the trimming of the first 8bp seemed to have worked. The overrepresented k-mers are now gone and everything seems ok. The tab _Sequence Length Distribution_ shows a warning but this is because after trimming by quality and complexity we expect that not all reads are going to have the same length.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "If you want to run all samples (not recommended on your desktop), do:\n",
    "\n",
    "> ``fastqc 01_trimmed/*.fastq.gz --noextract -o 00QC/trimmed``\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "### About quality control\n",
    "\n",
    "Lots of stuff can go wrong during sequencing; at any step from the preparation of the libraries to the interpretation of results. Even before that, if the design of the experiment isn't great, results won't be great. \n",
    "\n",
    "Thus, some things are easier to control than others; when analyzing the sequenced libraries it is a good practice to check the quality control of both raw and processed reads before delving into the mapping and subsequent steps.\n",
    "\n",
    "Here are some links that discuss some of these matters.  \n",
    "\n",
    "\n",
    "https://sequencing.qcfail.com/articles/position-specific-failures-of-flowcells/\n",
    "\n",
    "\n",
    "\n",
    "> # *Don't panic*\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "## 4. Alignment to a reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are sure our sequences have been cleaned, we can proceed to map them back to the a reference genome or transcriptome.\n",
    "\n",
    "### Get the data\n",
    "\n",
    "In this example we're using Arabidopsis data, so we need to download the fasta files corresponding to the chromosomes. If the fasta of your genome is splitted in different files you'll need to concatenate them into a single file.\n",
    "\n",
    "The _fasta.fa_ file for the index needs to have a format like:\n",
    "\n",
    "\\> Chr 1 <br>\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTG<br>\n",
    "\\> Chr 2<br>\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTG<br>\n",
    "\\> Chr N<br>\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTG<br>\n",
    "\n",
    "\n",
    "\n",
    "Luckyly there's a resource for that: go to the TAIR ftp site and get the data:\n",
    "\n",
    "> ftp://ftp.arabidopsis.org/home/tair/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas\n",
    "\n",
    "\n",
    "Also, we'll need a GFF file for the annotation (to assign counts to each gene). Go ahead and download the file form the TAIR's ftp site:\n",
    "\n",
    "> ftp://ftp.arabidopsis.org/home/tair/Genes/TAIR10_genome_release/TAIR10_gff3\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bowtie\n",
    "\n",
    "There are many mapping algorithms that we can use, depending on our type of data, some tools might be better than others. Also, depending on the computational power we have available, we might prefer some program over other.\n",
    "\n",
    "\n",
    "[Bowtie](http://bowtie-bio.sourceforge.net) and [Bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml) are widely use tools for hight-troughput sequencing mapping. They're designed to be fast, and can perform well on a desktop computer. Here we're dealing with short reads (\\<50bp); Bowtie1 (aka just Bowtie) peforms well with these type of reads. \n",
    "\n",
    "They're based on the __burrow wheeler transform__ algorithm used for compression. Check the wikipedia entry to know more: https://en.wikipedia.org/wiki/Burrows–Wheeler_transform.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Create the Index\n",
    "\n",
    "After downloading and concatenating the chromosome into a single file, create the index \n",
    "\n",
    "> `mkdir -p athGenome/bwt1_genome #use a subfolder in case you want to use the transcriptome instead of the genome`<br>\n",
    "> `bowtie-build meta/genome_ath_TAIRv10.fa athGenome/bwt1_genome/athIndex #athIndex will be the prefix for the files`<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Align!\n",
    "\n",
    "\n",
    "Check the bowtie manual to understand how it works and what are the parameters doing.\n",
    "\n",
    "\n",
    "> `mkdir -p AlignedReads/bwt1_genome #use a subfolder in case you want to use the transcriptome instead of the genome`<br>\n",
    "> ``for n in 01_trimmed/*test*.lane.clean.gz; do tmp=`basename $n`; tmp=${tmp%.lane.clean.gz}; echo Doing $tmp; gunzip -dc $n | bowtie -a --best --strata -n 1 -m 1 -p 4 --sam --tryhard athGenome/bwt1_genome/athIndex - -S AlignedReads/bwt1_genome/$tmp.sam ;done``\n",
    "\n",
    "\n",
    "The output gives us information on the mapping efficiency of our reads:\n",
    "\n",
    "\n",
    "\\# reads processed: 83003 <br>\n",
    "\\# reads with at least one reported alignment: 52950 (63.79%)<br>\n",
    "\\# reads that failed to align: 10537 (12.69%)<br>\n",
    "\\# reads with alignments suppressed due to -m: 19516 (23.51%)<br>\n",
    "Reported 52950 alignments to 1 output stream(s)<br>\n",
    "\n",
    "\n",
    "During the trimming/cleaning process we lost some of our reads (due to low quality, low complexity and other factors):\n",
    "__116997__ (reads that were thrown away, check the lint file in the trimmed folder) + __83003__ (usable, clean reads) = __200,000__ starting reads.\n",
    "\n",
    "However we have a pretty good alignment percentage (~64% of the reads that are left have a unique position in the genome).\n",
    "\n",
    "### Filter SAM file and convert to BAM.\n",
    "\n",
    "The SAM format contains the information of the genomic position of each of the reads. If we check the file we'll see that all the reads (83003) are present, regardless if they were uniquely mapped or not. We need to get rid of those that we don't want.\n",
    "\n",
    "> `grep -v \"@\" AlignedReads/bwt1_genome/testSeq.sam | wc -l` <br>\n",
    "> 83003\n",
    "\n",
    "\n",
    "Samtools allows us to filter these and to compress to another format (BAM), which compresses the information so files aren't huge.\n",
    "\n",
    "\n",
    "> ``for n in AlignedReads/bwt1_genome/*test*.sam; do tmp=`basename $n`; tmp=${tmp%.sam}; echo Doing $tmp; samtools view -q 30 -b -S $n > AlignedReads/bwt1_genome/$tmp.bam ;done``\n",
    "\n",
    "To check that the file removed the unwanted reads:\n",
    "\n",
    "> `samtools view AlignedReads/bwt1_genome/testSeq.bam | wc -l`\n",
    "> 52950 # This should be the same number in the uniquely aligned reads from the bowtie output.\n",
    "\n",
    "\n",
    "The compression from SAM to BAM helps us keep smaller files. In this example, the size goes from 15Mb (SAM) to only 2Mb (BAM). Imagine how big the files would be if we were working with the original full data.\n",
    "\n",
    "We can now go ahead and delete the .sam files to free disk space. \n",
    "\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "If you want to run all samples (not recommended on your desktop), do:\n",
    "\n",
    "> ``for n in AlignedReads/bwt1_genome/*.sam; do tmp=`basename $n`; tmp=${tmp%.sam}; echo Doing $tmp; samtools view -q 30 -b -S > AlignedReads/bwt1_genome/$tmp.bam ;done``\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 5. Count me in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So far we've protected our files against accidental edition or deletion, checked the quality before and after trimming, and mapped to the genome.\n",
    "\n",
    "A good fraction (~64%) of the reads are mapping to the genome. Now we want to know how many counts can we assign to each gene. \n",
    "\n",
    "As in the previous steps, there are different tools we can use. If you're more of an R person, the  [GenomicAlignments](http://www.bioconductor.org/packages/release/bioc/html/GenomicAlignments.html) package from bioconductor might interest you.\n",
    "\n",
    "For this example we'll use [HTSeq](www-huber.embl.de/users/anders/HTSeq/doc/count.html), a python-based tool.\n",
    "\n",
    "Regardless of the tool you use they have the same basic principle: having the genomic position of each read we want to compare to a reference of the annotated genes. We assign a read (count) to a gene if the overlap between them is significant.\n",
    "\n",
    "The annotation reference will be the GFF file we previously downloaded form TAIR.\n",
    "\n",
    "\n",
    "> mkdir -p Counts/bwt1_genome <br>\n",
    "\n",
    "> ``for n in AlignedReads/bwt1_genome/*test*.bam; do tmp=`basename $n`; tmp=${tmp%.bam}; echo Doing $tmp; samtools view -h $n | samtools sort -O sam | htseq-count -f sam --stranded yes --mode \"union\" --idattr ID --type gene - meta/TAIR10_withTransposons.gff > Counts/bwt1_genome/$tmp.txt;done\n",
    "Doing testSeq.bam``\n",
    "\n",
    "\n",
    "Check it worked:\n",
    "\n",
    "> ``head Counts/bwt1_genome/testSeq.txt`` <br>\n",
    "\n",
    "\n",
    "HTSeq gives a summary of the annotation at the end of the file, counting how many of the aligned reads didn't ovlerap with any of the genes in the GFF file or how many could've been assigned to more than one gene (ambiguous). These are not considered.  \n",
    "\n",
    "> ``tail Counts/bwt1_genome/testSeq.txt`` <br>\n",
    "\n",
    "__no_feature\t27537\n",
    "__ambiguous\t292\n",
    "__too_low_aQual\t0\n",
    "__not_aligned\t0\n",
    "__alignment_not_unique\t0\n",
    "\n",
    "We know that we have originally 52,950 uniquely mapped reads. And we have 27537+292 sequences that weren't counted as part of any gene. Then the number of effectively counted reads is:\n",
    "52950-(27537+292) = 25,121\n",
    "\n",
    "We can prove it by running the following code:\n",
    "> ``grep -v \"__\" Counts/bwt1_genome/testSeq.txt | cut -f2 | paste -sd+ - | bc`` <br>\n",
    "> 25121\n",
    "\n",
    "#### Count Matrix.\n",
    "Using R we can pull together each of the count files to create a matrix of counts for differential expression analysis.\n",
    "\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "If you want to run all samples (not recommended on your desktop), do:\n",
    "\n",
    "``for n in AlignedReads/bwt1_genome/*test*.bam; do tmp=`basename $n`; tmp=${tmp%.bam}; echo Doing $tmp; samtools view -h $n | samtools sort -O sam | htseq-count -f sam --stranded yes --mode \"union\" --idattr ID --type gene - meta/TAIR10_withTransposons.gff > Counts/bwt1_genome/$tmp.txt;done\n",
    "Doing testSeq.bam``\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## 5. Differential Gene Expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata file\n",
    "\n",
    "Personally, I like to use a file (.txt,.csv,.tsv format) where information about the experiment is stored. The more information, the better! \n",
    "\n",
    "For example if you know that the experiments were run in different days that information can go into the model and account for batch or other effects that could have an influence in the data.\n",
    "\n",
    "An example of how a good meta data looks:\n",
    "\n",
    "|File| Sample | Source | rep |\n",
    "|---|---| --- | --- |\n",
    "|SRR1463325| ML1pYFP-RCI2A (ML1Y)_replicate_1 | \tEpidermis_cells | r1 |\n",
    "|SRR1463326| ML1pYFP-RCI2A (ML1Y)_replicate_2 |\tEpidermis_cells | r2 |\n",
    "|SRR1463334| E1728GFP_(E1728G)_replicate_1  | Mature_guard_cells| r1|\n",
    "|SRR1463335| E1728GFP_(E1728G)_replicate_2 | Mature_guard_cells| r2 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following is an example of R code for differential expression using limma/voom.\n",
    "\n",
    "The raw counts and associated metadata files are in the github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "> library(edgeR)\n",
    "library(gplots)\n",
    "library(calibrate)\n",
    "library(RColorBrewer)\n",
    "library(limma)\n",
    "\n",
    "> GeneCounts <- read.csv(\"RawCounts_bwt1_genome.csv\",row.names = 1) #1 gene\n",
    "\n",
    "> meta <- read.csv(\"meta/meta.csv\",as.is = T,row.names = 1)\n",
    "\n",
    "\n",
    "> meta$SampleNameFull <-paste0(meta$Name,meta$Rep)\n",
    "colnames(GeneCounts) <- meta$SampleNameFull #Assign sample names to counts table\n",
    "cat(ncol(GeneCounts),\"samples in the data frame \\n\")\n",
    "ncol(GeneCounts) == nrow(meta)\n",
    "dim(GeneCounts)\n",
    "\n",
    "\n",
    "> cat(\"Removing genes with 0 counts on all conditions \\n\")\n",
    "cat(\"Initial number of genes:\",nrow(GeneCounts),\"\\n\")\n",
    "rmIDX <- which(rowSums(GeneCounts) == 0)\n",
    "if (length(rmIDX) != 0){\n",
    "  cat(\"Removing\",length(rmIDX),\"genes \\n\")\n",
    "  GeneCounts <- GeneCounts[-rmIDX,]\n",
    "  cat(\"Remaining number of genes:\",nrow(GeneCounts),\"\\n\")\n",
    "} else {\n",
    "  cat(\"No genes with 0 counts on all  \\n\")\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "> design <- model.matrix(~0+Name, data =meta)#+Lane\n",
    "colnames(design) <- gsub(\"Name|:|-|/|Group\",\"\",colnames(design))\n",
    "head(design)\n",
    "\n",
    "\n",
    "> dge <- DGEList(counts=GeneCounts,remove.zeros = T) \n",
    "range(table(meta$Name))\n",
    "sampleMin <- min(table(meta$Name))\n",
    "minCPM <- 1\n",
    "isexpr <- rowSums(cpm(dge) > minCPM) >= sampleMin #Make sure to use the minimum number of reps\n",
    "table(isexpr)\n",
    "cat(\"Removing lowly expressed genes ( <\",minCPM,\"cpm on at least\",sampleMin,\"samples) \\n\")\n",
    "#Remove lowly expressed genes\n",
    "cat(\"Removing\",table(isexpr)[1],\"genes \\n\")\n",
    "cat(\"Remaining number of genes:\",table(isexpr)[2],\"\\n\")\n",
    "dge <- dge[isexpr,,keep.lib.size = FALSE]\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "> #Optional, do TMM along with voom\n",
    "dge <- calcNormFactors(dge)\n",
    "v <- voomWithQualityWeights(dge, design=design, normalization=\"quantile\", plot=TRUE)\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "> ##Check samples after normalization\n",
    "library(RColorBrewer)\n",
    "\n",
    "> ##-- Produce graphics\n",
    "Targets <- meta\n",
    "col.Source <- c(\"steelblue4\", \"skyblue\")\n",
    "> ##Boxplot\n",
    "boxplot(v$E, range=0,col=col.Source[as.factor(meta$Name)], \n",
    "        ylab=\"log2[counts]\", xlab=\"sample\", main=\"voom normalized counts\",\n",
    "        cex.axis=0.5,las=2)\n",
    "\n",
    "\n",
    "> ##MDS plots with glimma\n",
    "library(Glimma)\n",
    "glMDSPlot(v, labels=meta$SampleNameFull, groups=Targets[,c(\"Name\")],\n",
    "          folder=paste0(outDir,\"/glimma\"),\n",
    "          launch=T)\n",
    "\n",
    "<hr>\n",
    "\n",
    "> ##Fit\n",
    "v2 <- lmFit(v, design)\n",
    "###do contrasts\n",
    "contrastMatrix <- makeContrasts(\n",
    "   \"EPIvMGC\"=(EPI-MGC),\n",
    "  levels = design)\n",
    "\n",
    "> fit2 <- contrasts.fit(v2, contrastMatrix)\n",
    "fit2 <- eBayes(fit2)\n",
    "\n",
    "<hr>\n",
    "\n",
    "> ##Venn diagrams\n",
    "results <- decideTests(fit2)#,lfc = logCut,p.value = pValCut)\n",
    "summary(results)\n",
    "vennDiagram(results,include = c(\"up\",\"down\"))\n",
    "\n",
    "\n",
    "> ##Get normalized expression\n",
    "voomNormalizedExpression <- v$E\n",
    "\n",
    "\n",
    "<hr>\n",
    "> ##If gene alias information is available:\n",
    "geneAlias <- read.delim(\"meta/gene_aliases.txt\",header = T, fill = NA,stringsAsFactors = F)\n",
    "geneAlias <- split(geneAlias,geneAlias$locus_name)\n",
    "AGI2Symbol <- lapply(geneAlias, function(x){\n",
    "  idx <- grepl(\"^(?!A[Tt])\",x[,\"symbol\"],perl = T); #Negates genes starting with At or AT\n",
    "  if (all(idx == F)){\n",
    "    paste(x[,\"symbol\"],collapse = \"/\")\n",
    "  } else {\n",
    "    symbols <- paste(x[idx,\"symbol\"],collapse = \"/\") }\n",
    "})\n",
    "AGI2Symbol <- unlist(AGI2Symbol)\n",
    "head(AGI2Symbol)\n",
    "\n",
    "<hr>\n",
    "\n",
    "> ##-- Do DGE\n",
    "logCut <- 1\n",
    "pValCut <- 0.05\n",
    "uniqContrasts <- colnames(contrastMatrix)\n",
    "\n",
    "> cat(\"Genotypes that will be analyzed:\" ,paste0(uniqContrasts),\"\\n\")\n",
    "\n",
    "> ###Prepare lists\n",
    "DEList <- list()\n",
    "DESignificant <- list()\n",
    "\n",
    "> for (contrast in uniqContrasts){\n",
    "  cat(\" - - - \\n\")\n",
    "  dropContrasts <- contrast\n",
    "  contrastNames <- contrast#colnames(fit2$coefficients)[dropContrasts]\n",
    "  cat(\"Contrast:\", paste0(contrastNames),\"\\n\")\n",
    "  tmp <- topTable(fit2, coef=dropContrasts,number = Inf,sort.by = \"none\")\n",
    "  tmp[,\"Symbol\"] <- rownames(tmp)\n",
    "  \n",
    "  > #-- Add gene symbols\n",
    "  Genes <- rownames(tmp)\n",
    "  idx <- intersect(names(AGI2Symbol),Genes)\n",
    "  tmp[idx,\"Symbol\"] <- AGI2Symbol[idx]\n",
    "    \n",
    "  >###Change names of columns\n",
    "  #Get indices of columns that correspond to logFC\n",
    "  #tmpIDX <- grep(paste(contrastNames,collapse=\"|\"),colnames(tmp))\n",
    "  colnames(tmp) <- paste(contrast,colnames(tmp),sep = \".\")\n",
    "  DEList[[contrast]] <- tmp\n",
    "  \n",
    " >##Filter\n",
    "  tmpIDX <- grep(\"adj.P.Val\",colnames(tmp))\n",
    "  tmpSign <- tmp[tmp[,tmpIDX] < pValCut,] \n",
    "  nrow(tmpSign)\n",
    "  DESignificant[[contrast]] <- tmpSign\n",
    "\n",
    "  > cat (\"Number of DEGs on\",contrast,\":\",nrow(tmpSign),\"\\n\")\n",
    "  }  \n",
    "\n",
    "\n",
    "> sapply(DEList,function(x){table(x[,grep(\"adj.P.Val\",colnames(x))] < 0.05)})\n",
    "> significantDE <- lapply(DEList,function(x){ x[x[,grep(\"adj.P.Val\",colnames(x))] < 0.05,] })\n",
    "> sapply(significantDE,nrow)\n",
    "<hr>\n",
    "\n",
    "\n",
    "> ##Get the DE genes.\n",
    "DE <- significantDE[[1]]\n",
    "head(DE)\n",
    "\n",
    "\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "### Resources\n",
    "\n",
    "* About duplication in RNAseq \n",
    "    * http://proteo.me.uk/2013/09/a-new-way-to-look-at-duplication-in-fastqc-v0-11/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.ebi.ac.uk/research/enright/software/kraken\n",
    "* http://hannonlab.cshl.edu/fastx_toolkit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "github: rodriguezmDNA <br>\n",
    "created: 25.07.17_jrm <br>\n",
    "last revision: 25.07.17_jrm <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
